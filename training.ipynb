{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2208b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from transformers import ViTForImageClassification, ViTFeatureExtractor\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set device to CUDA if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ==========================\n",
    "# Dataset Configuration\n",
    "# ==========================\n",
    "# Kaggle dataset path\n",
    "dataset_path = \"/kaggle/input/nthuddd2/train_data\"  # Update this path if needed\n",
    "print(f\"Dataset path: {dataset_path}\")\n",
    "\n",
    "# Check if dataset exists\n",
    "if not os.path.exists(dataset_path):\n",
    "    raise FileNotFoundError(f\"Dataset not found at {dataset_path}. Please ensure the dataset is uploaded to Kaggle.\")\n",
    "\n",
    "# ==========================\n",
    "# Custom Dataset Class\n",
    "# ==========================\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.classes = sorted(os.listdir(root_dir))  # ['drowsy', 'notdrowsy']\n",
    "        \n",
    "        # Load image paths and labels\n",
    "        for label, class_name in enumerate(self.classes):\n",
    "            class_dir = os.path.join(root_dir, class_name)\n",
    "            if not os.path.isdir(class_dir):\n",
    "                raise FileNotFoundError(f\"Class directory {class_dir} not found.\")\n",
    "            for file_name in os.listdir(class_dir):\n",
    "                self.image_paths.append(os.path.join(class_dir, file_name))\n",
    "                self.labels.append(label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        try:\n",
    "            image = Image.open(image_path).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                image = self.transform(image)\n",
    "            return {\"pixel_values\": image, \"labels\": torch.tensor(label, dtype=torch.long)}\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image {image_path}: {e}\")\n",
    "            return None\n",
    "\n",
    "# ==========================\n",
    "# Define Transformations\n",
    "# ==========================\n",
    "# Load feature extractor for ViT\n",
    "model_name = \"google/vit-base-patch16-224-in21k\"\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
    "\n",
    "# Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=feature_extractor.image_mean, std=feature_extractor.image_std),\n",
    "])\n",
    "\n",
    "# ==========================\n",
    "# Load Dataset and Split into Train/Validation\n",
    "# ==========================\n",
    "dataset = CustomDataset(dataset_path, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "val_size = len(dataset) - train_size  # 20% for validation\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=2)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=2)\n",
    "\n",
    "# ==========================\n",
    "# Load Model\n",
    "# ==========================\n",
    "model = ViTForImageClassification.from_pretrained(model_name, num_labels=2)  # 2 classes: drowsy, notdrowsy\n",
    "model.to(device)\n",
    "\n",
    "# ==========================\n",
    "# Define Training Setup\n",
    "# ==========================\n",
    "optimizer = AdamW(model.parameters(), lr=0.0002)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "# Training Loop\n",
    "num_epochs = 10\n",
    "best_loss = float(\"inf\")\n",
    "early_stopping_patience = 5\n",
    "early_stopping_counter = 0\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Training loop with tqdm progress bar\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Training)\"):\n",
    "        if batch is None:\n",
    "            continue  # Skip problematic batches\n",
    "\n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.logits, 1)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    # Calculate training metrics\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "    print(f\"Epoch {epoch+1}: Training Loss: {avg_loss:.4f}, Training Accuracy: {train_accuracy:.2f}%\")\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    val_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} (Validation)\"):\n",
    "            if batch is None:\n",
    "                continue  # Skip problematic batches\n",
    "\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "            loss = outputs.loss\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.logits, 1)\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "    # Calculate validation metrics\n",
    "    val_accuracy = 100 * val_correct / val_total\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    print(f\"Epoch {epoch+1}: Validation Loss: {avg_val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "    # Save Best Model\n",
    "    if avg_val_loss < best_loss:\n",
    "        best_loss = avg_val_loss\n",
    "        early_stopping_counter = 0\n",
    "        torch.save(model.state_dict(), \"/kaggle/working/best_model.pth\")\n",
    "        print(\"Saved best model.\")\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= early_stopping_patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}.\")\n",
    "            break\n",
    "\n",
    "# ==========================\n",
    "# Save Model to Kaggle Output Folder\n",
    "# ==========================\n",
    "model.save_pretrained(\"/kaggle/working/trained_vit_model\")\n",
    "feature_extractor.save_pretrained(\"/kaggle/working/trained_vit_model\")\n",
    "print(\"Model and feature extractor saved to /kaggle/working/trained_vit_model\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
